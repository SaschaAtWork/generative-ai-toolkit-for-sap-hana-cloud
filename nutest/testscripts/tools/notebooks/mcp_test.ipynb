{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead72e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.langchain import init_llm\n",
    "import pandas as pd\n",
    "from hana_ml import dataframe\n",
    "from hana_ai.tools.toolkit import HANAMLToolkit\n",
    "\n",
    "\n",
    "connection_context = dataframe.ConnectionContext(userkey=\"RaysKey\")\n",
    "\n",
    "llm = init_llm('gpt-4-32k', temperature=0.0, max_tokens=1800)\n",
    "toolkit = HANAMLToolkit(connection_context, used_tools='all', return_direct={\"fetch_data\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407a5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:âš ï¸  Unsupported stdio, switching to SSE\n",
      "WARNING:root:âš ï¸  Port 12345 occupied, trying next port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [9064]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:12346 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "toolkit.launch_mcp_server(server_name=\"test\", sse_port=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fc9938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:61639 - \"GET /sse HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:61641 - \"POST /messages/?session_id=cdc7182578ee4178a90e13ce6009d60a HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:61641 - \"POST /messages/?session_id=cdc7182578ee4178a90e13ce6009d60a HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:61641 - \"POST /messages/?session_id=cdc7182578ee4178a90e13ce6009d60a HTTP/1.1\" 202 Accepted\n",
      "âœ… æˆåŠŸè·å– 16 ä¸ªå·¥å…·:\n",
      "  ğŸ› ï¸ åç§°: accuracy_measure\n",
      "  ğŸ“ æè¿°: To compute the accuracy measure using true and predict tables.\n",
      "  ğŸ› ï¸ åç§°: additive_model_forecast_fit_and_save\n",
      "  ğŸ“ æè¿°: To fit the additive model forecast and save the model in model storage.\n",
      "  ğŸ› ï¸ åç§°: additive_model_forecast_load_model_and_predict\n",
      "  ğŸ“ æè¿°: To load the additive model forecast from model storage and predict.\n",
      "  ğŸ› ï¸ åç§°: automatic_timeseries_fit_and_save\n",
      "  ğŸ“ æè¿°: To fit an AutomaticTimeseries model and save it in the model storage.\n",
      "  ğŸ› ï¸ åç§°: automatic_timeseries_load_model_and_predict\n",
      "  ğŸ“ æè¿°: To load a model and do the prediction using automatic timeseries model.\n",
      "  ğŸ› ï¸ åç§°: automatic_timeseries_load_model_and_score\n",
      "  ğŸ“ æè¿°: To load a model and do the scoring for automatic timeseries.\n",
      "  ğŸ› ï¸ åç§°: cap_artifacts\n",
      "  ğŸ“ æè¿°: To generate CAP artifacts for a given model from model storage. \n",
      "  ğŸ› ï¸ åç§°: fetch_data\n",
      "  ğŸ“ æè¿°: Fetch data from a given table.\n",
      "  ğŸ› ï¸ åç§°: forecast_line_plot\n",
      "  ğŸ“ æè¿°: To generate line plot for the forecasted result. \n",
      "  ğŸ› ï¸ åç§°: intermittent_forecast\n",
      "  ğŸ“ æè¿°: To generate forecast for the intermittent demand dataset. \n",
      "  ğŸ› ï¸ åç§°: list_models\n",
      "  ğŸ“ æè¿°: List all models in the model storage.\n",
      "  ğŸ› ï¸ åç§°: ts_dataset_report\n",
      "  ğŸ“ æè¿°: To generate timeseries report for a given HANA table. \n",
      "  ğŸ› ï¸ åç§°: ts_check\n",
      "  ğŸ“ æè¿°: To check the time series data for stationarity, intermittent, trend and seasonality.\n",
      "  ğŸ› ï¸ åç§°: ts_outlier_detection\n",
      "  ğŸ“ æè¿°: To detect outliers in time series data. \n",
      "  ğŸ› ï¸ åç§°: classification_tool\n",
      "  ğŸ“ æè¿°: To train the classification model or to predict on the classification model.\n",
      "  ğŸ› ï¸ åç§°: regression_tool\n",
      "  ğŸ“ æè¿°: To train the regression model or to predict on the regression model.\n",
      "âœ… å·¥å…·åˆ—è¡¨è·å–æˆåŠŸï¼\n",
      "ğŸ” æ­£åœ¨è°ƒç”¨ fetch_data å·¥å…·...\n",
      "INFO:     127.0.0.1:61641 - \"POST /messages/?session_id=cdc7182578ee4178a90e13ce6009d60a HTTP/1.1\" 202 Accepted\n"
     ]
    }
   ],
   "source": [
    "from mcp.client.sse import sse_client  # SSEåè®®å®¢æˆ·ç«¯\n",
    "from mcp import ClientSession  # MCPä¼šè¯ç®¡ç†\n",
    "\n",
    "async def get_mcp_tools():\n",
    "    \"\"\"è·å–å¹¶æ‰“å°MCPæœåŠ¡çš„æ‰€æœ‰å·¥å…·åˆ—è¡¨\"\"\"\n",
    "    try:\n",
    "        # 1. å»ºç«‹SSEè¿æ¥\n",
    "        async with sse_client(\"http://localhost:12346/sse\") as streams:\n",
    "            # 2. åˆ›å»ºä¼šè¯\n",
    "            async with ClientSession(*streams) as session:\n",
    "                await session.initialize()  # åˆå§‹åŒ–ä¼šè¯\n",
    "                \n",
    "                # 3. è·å–å·¥å…·åˆ—è¡¨\n",
    "                tools = await session.list_tools()\n",
    "                print(f\"âœ… æˆåŠŸè·å– {len(tools.tools)} ä¸ªå·¥å…·:\")\n",
    "                \n",
    "                # 4. æ‰“å°å·¥å…·è¯¦æƒ…\n",
    "                for tool in tools.tools:\n",
    "                    print(f\"  ğŸ› ï¸ åç§°: {tool.name}\")\n",
    "                    print(f\"  ğŸ“ æè¿°: {tool.description}\")\n",
    "\n",
    "                print(\"âœ… å·¥å…·åˆ—è¡¨è·å–æˆåŠŸï¼\")\n",
    "\n",
    "                # 5. è°ƒç”¨fetch_dataå·¥å…·ç¤ºä¾‹\n",
    "                try:\n",
    "                    # è°ƒç”¨å·¥å…·\n",
    "                    print(\"ğŸ” æ­£åœ¨è°ƒç”¨ fetch_data å·¥å…·...\")\n",
    "                    result = await session.call_tool(name=\"fetch_data\", arguments={\n",
    "                        \"kwargs\": {\n",
    "                            \"table_name\": \"PAL_COVID_DATA_TBL\",  # ç¡®ä¿é”®åå®Œå…¨åŒ¹é…\n",
    "                            \"top_n\": 5\n",
    "                        }\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    # æ•è·å…·ä½“å¼‚å¸¸ç±»å‹ï¼ˆå¦‚ValidationErrorï¼‰\n",
    "                    print(f\"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {type(e).__name__}: {str(e)}\")\n",
    "                return result\n",
    "\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è°ƒç”¨å¤±è´¥: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œå¼‚æ­¥å‡½æ•°\n",
    "result = await get_mcp_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e54519e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Date  Confirmed  Recovered  Deaths  Increase rate\n",
      "1/22/2020        555         28      17            NaN\n",
      "1/23/2020        654         30      18      17.837838\n",
      "1/24/2020        941         36      26      43.883792\n",
      "1/25/2020       1434         39      42      52.391073\n",
      "1/26/2020       2118         52      56      47.698745\n"
     ]
    }
   ],
   "source": [
    "print(result.content[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

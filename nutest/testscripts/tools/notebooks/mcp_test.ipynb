{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead72e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.langchain import init_llm\n",
    "import pandas as pd\n",
    "from hana_ml import dataframe\n",
    "from hana_ai.tools.toolkit import HANAMLToolkit\n",
    "\n",
    "\n",
    "connection_context = dataframe.ConnectionContext(userkey=\"RaysKey\")\n",
    "\n",
    "llm = init_llm('gpt-4-32k', temperature=0.0, max_tokens=1800)\n",
    "toolkit = HANAMLToolkit(connection_context, used_tools='all', return_direct={\"fetch_data\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407a5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:âš ï¸  Unsupported stdio, switching to SSE\n",
      "WARNING:root:âš ï¸  Port 12345 occupied, trying next port\n",
      "WARNING:root:âš ï¸  Port 12346 occupied, trying next port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [7024]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:12347 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "toolkit.launch_mcp_server(server_name=\"test\", sse_port=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fc9938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:56092 - \"GET /sse HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:56094 - \"POST /messages/?session_id=5725f34d8d1540fc95b6a97be7c7d704 HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:56094 - \"POST /messages/?session_id=5725f34d8d1540fc95b6a97be7c7d704 HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:56094 - \"POST /messages/?session_id=5725f34d8d1540fc95b6a97be7c7d704 HTTP/1.1\" 202 Accepted\n",
      "âœ… æˆåŠŸè·å– 16 ä¸ªå·¥å…·:\n",
      "  ğŸ› ï¸ åç§°: accuracy_measure\n",
      "  ğŸ“ æè¿°: To compute the accuracy measure using true and predict tables.\n",
      "  ğŸ› ï¸ åç§°: additive_model_forecast_fit_and_save\n",
      "  ğŸ“ æè¿°: To fit the additive model forecast and save the model in model storage.\n",
      "  ğŸ› ï¸ åç§°: additive_model_forecast_load_model_and_predict\n",
      "  ğŸ“ æè¿°: To load the additive model forecast from model storage and predict.\n",
      "  ğŸ› ï¸ åç§°: automatic_timeseries_fit_and_save\n",
      "  ğŸ“ æè¿°: To fit an AutomaticTimeseries model and save it in the model storage.\n",
      "  ğŸ› ï¸ åç§°: automatic_timeseries_load_model_and_predict\n",
      "  ğŸ“ æè¿°: To load a model and do the prediction using automatic timeseries model.\n",
      "  ğŸ› ï¸ åç§°: automatic_timeseries_load_model_and_score\n",
      "  ğŸ“ æè¿°: To load a model and do the scoring for automatic timeseries.\n",
      "  ğŸ› ï¸ åç§°: cap_artifacts\n",
      "  ğŸ“ æè¿°: To generate CAP artifacts for a given model from model storage. \n",
      "  ğŸ› ï¸ åç§°: fetch_data\n",
      "  ğŸ“ æè¿°: Fetch data from a given table.\n",
      "  ğŸ› ï¸ åç§°: forecast_line_plot\n",
      "  ğŸ“ æè¿°: To generate line plot for the forecasted result. \n",
      "  ğŸ› ï¸ åç§°: intermittent_forecast\n",
      "  ğŸ“ æè¿°: To generate forecast for the intermittent demand dataset. \n",
      "  ğŸ› ï¸ åç§°: list_models\n",
      "  ğŸ“ æè¿°: List all models in the model storage.\n",
      "  ğŸ› ï¸ åç§°: ts_dataset_report\n",
      "  ğŸ“ æè¿°: To generate timeseries report for a given HANA table. \n",
      "  ğŸ› ï¸ åç§°: ts_check\n",
      "  ğŸ“ æè¿°: To check the time series data for stationarity, intermittent, trend and seasonality.\n",
      "  ğŸ› ï¸ åç§°: ts_outlier_detection\n",
      "  ğŸ“ æè¿°: To detect outliers in time series data. \n",
      "  ğŸ› ï¸ åç§°: classification_tool\n",
      "  ğŸ“ æè¿°: To train the classification model or to predict on the classification model.\n",
      "  ğŸ› ï¸ åç§°: regression_tool\n",
      "  ğŸ“ æè¿°: To train the regression model or to predict on the regression model.\n"
     ]
    }
   ],
   "source": [
    "from mcp.client.sse import sse_client  # SSEåè®®å®¢æˆ·ç«¯\n",
    "from mcp import ClientSession  # MCPä¼šè¯ç®¡ç†\n",
    "\n",
    "async def get_mcp_tools():\n",
    "    \"\"\"è·å–å¹¶æ‰“å°MCPæœåŠ¡çš„æ‰€æœ‰å·¥å…·åˆ—è¡¨\"\"\"\n",
    "    try:\n",
    "        # 1. å»ºç«‹SSEè¿æ¥\n",
    "        async with sse_client(\"http://localhost:12347/sse\") as streams:\n",
    "            # 2. åˆ›å»ºä¼šè¯\n",
    "            async with ClientSession(*streams) as session:\n",
    "                await session.initialize()  # åˆå§‹åŒ–ä¼šè¯\n",
    "                \n",
    "                # 3. è·å–å·¥å…·åˆ—è¡¨\n",
    "                tools = await session.list_tools()\n",
    "                print(f\"âœ… æˆåŠŸè·å– {len(tools.tools)} ä¸ªå·¥å…·:\")\n",
    "                \n",
    "                # 4. æ‰“å°å·¥å…·è¯¦æƒ…\n",
    "                for tool in tools.tools:\n",
    "                    print(f\"  ğŸ› ï¸ åç§°: {tool.name}\")\n",
    "                    print(f\"  ğŸ“ æè¿°: {tool.description}\")\n",
    "                return tools.tools\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è°ƒç”¨å¤±è´¥: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œå¼‚æ­¥å‡½æ•°\n",
    "tools = await get_mcp_tools()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
